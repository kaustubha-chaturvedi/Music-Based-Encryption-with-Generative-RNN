{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vQ_BfIxFu7T_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras import layers as ls\n",
        "from keras import models as md\n",
        "import numpy as np\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Bb10J9vvlD"
      },
      "source": [
        "# **Training Model on data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgs2Edhv9dS"
      },
      "source": [
        "## **Create Model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qtppJxKsIl6f"
      },
      "outputs": [],
      "source": [
        "def trainingModel(uniques,batchSize,seqSize):\n",
        "    model = md.Sequential()\n",
        "    model.add(ls.Embedding(uniques, 512, batch_input_shape=(batchSize, seqSize)))\n",
        "\n",
        "    model.add(ls.LSTM(256, return_sequences=True, stateful=True))\n",
        "    model.add(ls.Dropout(0.2))\n",
        "    model.add(ls.LSTM(256, return_sequences=True, stateful=True))\n",
        "    model.add(ls.Dropout(0.2))\n",
        "    model.add(ls.LSTM(256, return_sequences=True, stateful=True))\n",
        "    model.add(ls.Dropout(0.2))\n",
        "    \n",
        "    model.add(ls.TimeDistributed(ls.Dense(uniques))) \n",
        "    model.add(ls.Activation('softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Tdx21XwJH2"
      },
      "source": [
        "## **Model Checkpoint Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2n7SenZ7KgEU"
      },
      "outputs": [],
      "source": [
        "def save(cp, model):\n",
        "    model.save_weights(f'{cp}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZYPakm0wQQX"
      },
      "source": [
        "## **Batch Division and Training Function with SaveBestModel Implemented**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SJFEMFu6LV32"
      },
      "outputs": [],
      "source": [
        "def batcheRead(T, uniques,batchSize,seqSize):\n",
        "    length = T.shape[0];\n",
        "    bChr = int(length / batchSize);\n",
        "\n",
        "    for start in range(0, bChr - seqSize, seqSize):\n",
        "        X = np.zeros((batchSize, seqSize))\n",
        "        Y = np.zeros((batchSize, seqSize, uniques))\n",
        "        for bIdx in range(0, batchSize): \n",
        "            for i in range(0, seqSize): \n",
        "                X[bIdx, i] = T[bChr * bIdx + start + i]  \n",
        "                Y[bIdx, i, T[bChr * bIdx + start + i + 1]] = 1\n",
        "        yield X, Y\n",
        "\n",
        "def train(model,epochs,cp,charIndex,data,batchSize,seqSize):\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    trainData = np.asarray([charIndex[c] for c in data],dtype=np.int32)\n",
        "    steps_per_epoch=int((len(trainData)/batchSize-1)/seqSize)\n",
        "    epochNum, lossNum, accNum = [], [float('inf')], [float('-inf')]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epochNum.append(epoch+1)\n",
        "        losses, accs = [], []\n",
        "\n",
        "        for i, (X, Y) in enumerate(batcheRead(trainData, len(charIndex),batchSize,seqSize)):\n",
        "            loss, acc = model.train_on_batch(X, Y)\n",
        "            losses.append(loss)\n",
        "            accs.append(acc)\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{epochs}: loss = {loss}, acc = {acc}')\n",
        "\n",
        "        if  accNum[-1]<acc and loss<lossNum[-1]:\n",
        "            save(cp, model)\n",
        "            print(f'Saved to checkpoint {cp}.h5 accuracy increased from {accNum[-1]} to {acc}')\n",
        "        lossNum.append(loss)\n",
        "        accNum.append(acc)\n",
        "    return {\"loss\":lossNum,\"accuracy\":accNum}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFPHk0S7yeHx"
      },
      "source": [
        "# **Generative Model Based on Previous model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwQ0uIT-yooU"
      },
      "source": [
        "## **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ihtLPqeDung"
      },
      "outputs": [],
      "source": [
        "def createSeqModel(ch):\n",
        "    model = md.Sequential()\n",
        "    \n",
        "    model.add(ls.Embedding(input_dim = ch, output_dim = 512, batch_input_shape = (1, 1))) \n",
        "  \n",
        "    model.add(ls.LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(ls.Dropout(0.2))\n",
        "    \n",
        "    model.add(ls.LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(ls.Dropout(0.2))\n",
        "    \n",
        "    model.add(ls.LSTM(256, stateful = True)) \n",
        "    model.add(ls.Dropout(0.2))\n",
        "    \n",
        "    model.add((ls.Dense(ch)))\n",
        "    model.add(ls.Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi5YU_3Oyv4v"
      },
      "source": [
        "## **Generator Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k7yARO4NFyej"
      },
      "outputs": [],
      "source": [
        "def generateSeq(seqSize, modelName,indexChar):\n",
        "    ch = len(indexChar)\n",
        "    model = createSeqModel(ch)\n",
        "    model.load_weights(f'{modelName}.h5')\n",
        "     \n",
        "    ind = [0]\n",
        "    \n",
        "    for _ in range(seqSize):\n",
        "        batch = np.zeros((1, 1))\n",
        "        batch[0, 0] = ind[-1]\n",
        "        \n",
        "        predictedProbs = model.predict_on_batch(batch).ravel()\n",
        "        sample = np.random.choice(range(ch), size = 1, p = predictedProbs)\n",
        "        \n",
        "        ind.append(sample[0])\n",
        "    \n",
        "    seq = ''.join(indexChar[c] for c in ind)\n",
        "    \n",
        "    cnt = 0\n",
        "    for i in seq:\n",
        "        cnt += 1\n",
        "        if i == \"\\n\":\n",
        "            break\n",
        "    seq = seq[cnt:]\n",
        "    cnt = 0\n",
        "    for i in seq:\n",
        "        cnt += 1\n",
        "        if i == \"\\n\" and seq[cnt] == \"\\n\":\n",
        "            break\n",
        "    seq = seq[:cnt]\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "bP-cgLQBy75p",
        "outputId": "3c5ee6cd-8bc1-48a2-ac13-c0479c386e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e4611d1-e256-4842-be75-252626dda779\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e4611d1-e256-4842-be75-252626dda779\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving input.txt to input.txt\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(r'/content/data'):\n",
        "    os.makedirs(r'/content/data')\n",
        "%cd /content/data\n",
        "files.upload()\n",
        "file=open(r'/content/data/input.txt','r')\n",
        "data=file.read()\n",
        "file.close()\n",
        "charIndex = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
        "indexChar = {v:k for (k,v) in charIndex.items()}\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CmKRxkJRqw8",
        "outputId": "6e6cd21c-a5c8-4176-901c-c1b0708ea7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: loss = 2.644301652908325, acc = 0.30078125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from -inf to 0.30078125\n",
            "Epoch 2/50: loss = 1.1079487800598145, acc = 0.6533203125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.30078125 to 0.6533203125\n",
            "Epoch 3/50: loss = 0.6866281032562256, acc = 0.7666015625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.6533203125 to 0.7666015625\n",
            "Epoch 4/50: loss = 0.5945200324058533, acc = 0.791015625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.7666015625 to 0.791015625\n",
            "Epoch 5/50: loss = 0.5301041007041931, acc = 0.8115234375\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.791015625 to 0.8115234375\n",
            "Epoch 6/50: loss = 0.48777133226394653, acc = 0.8212890625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8115234375 to 0.8212890625\n",
            "Epoch 7/50: loss = 0.4526677131652832, acc = 0.837890625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8212890625 to 0.837890625\n",
            "Epoch 8/50: loss = 0.4440125823020935, acc = 0.8349609375\n",
            "Epoch 9/50: loss = 0.4006364345550537, acc = 0.8525390625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8349609375 to 0.8525390625\n",
            "Epoch 10/50: loss = 0.397565633058548, acc = 0.8583984375\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8525390625 to 0.8583984375\n",
            "Epoch 11/50: loss = 0.38555702567100525, acc = 0.8525390625\n",
            "Epoch 12/50: loss = 0.367611289024353, acc = 0.859375\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8525390625 to 0.859375\n",
            "Epoch 13/50: loss = 0.35755908489227295, acc = 0.857421875\n",
            "Epoch 14/50: loss = 0.3429812788963318, acc = 0.876953125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.857421875 to 0.876953125\n",
            "Epoch 15/50: loss = 0.3322288990020752, acc = 0.873046875\n",
            "Epoch 16/50: loss = 0.3168789744377136, acc = 0.8876953125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.873046875 to 0.8876953125\n",
            "Epoch 17/50: loss = 0.2980818450450897, acc = 0.8896484375\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8876953125 to 0.8896484375\n",
            "Epoch 18/50: loss = 0.3025629222393036, acc = 0.8818359375\n",
            "Epoch 19/50: loss = 0.2750088572502136, acc = 0.8994140625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8818359375 to 0.8994140625\n",
            "Epoch 20/50: loss = 0.2651728689670563, acc = 0.90625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.8994140625 to 0.90625\n",
            "Epoch 21/50: loss = 0.25424063205718994, acc = 0.91015625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.90625 to 0.91015625\n",
            "Epoch 22/50: loss = 0.23395489156246185, acc = 0.916015625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.91015625 to 0.916015625\n",
            "Epoch 23/50: loss = 0.2337193340063095, acc = 0.9140625\n",
            "Epoch 24/50: loss = 0.22102046012878418, acc = 0.9189453125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9140625 to 0.9189453125\n",
            "Epoch 25/50: loss = 0.20421689748764038, acc = 0.9267578125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9189453125 to 0.9267578125\n",
            "Epoch 26/50: loss = 0.1956915706396103, acc = 0.931640625\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9267578125 to 0.931640625\n",
            "Epoch 27/50: loss = 0.19871649146080017, acc = 0.9248046875\n",
            "Epoch 28/50: loss = 0.18526282906532288, acc = 0.9345703125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9248046875 to 0.9345703125\n",
            "Epoch 29/50: loss = 0.16917452216148376, acc = 0.9345703125\n",
            "Epoch 30/50: loss = 0.15892067551612854, acc = 0.9482421875\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9345703125 to 0.9482421875\n",
            "Epoch 31/50: loss = 0.1548009216785431, acc = 0.9482421875\n",
            "Epoch 32/50: loss = 0.159169003367424, acc = 0.9453125\n",
            "Epoch 33/50: loss = 0.1418747901916504, acc = 0.95703125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9453125 to 0.95703125\n",
            "Epoch 34/50: loss = 0.144277885556221, acc = 0.9521484375\n",
            "Epoch 35/50: loss = 0.1361122876405716, acc = 0.951171875\n",
            "Epoch 36/50: loss = 0.13737818598747253, acc = 0.94921875\n",
            "Epoch 37/50: loss = 0.13224460184574127, acc = 0.95703125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.94921875 to 0.95703125\n",
            "Epoch 38/50: loss = 0.13060256838798523, acc = 0.953125\n",
            "Epoch 39/50: loss = 0.12980934977531433, acc = 0.955078125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.953125 to 0.955078125\n",
            "Epoch 40/50: loss = 0.11826159060001373, acc = 0.9580078125\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.955078125 to 0.9580078125\n",
            "Epoch 41/50: loss = 0.11978951096534729, acc = 0.9560546875\n",
            "Epoch 42/50: loss = 0.10362467914819717, acc = 0.9609375\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.9560546875 to 0.9609375\n",
            "Epoch 43/50: loss = 0.109835185110569, acc = 0.962890625\n",
            "Epoch 44/50: loss = 0.114879310131073, acc = 0.9638671875\n",
            "Epoch 45/50: loss = 0.11209728568792343, acc = 0.962890625\n",
            "Epoch 46/50: loss = 0.0865999236702919, acc = 0.9638671875\n",
            "Saved to checkpoint modelV1.h5 accuracy increased from 0.962890625 to 0.9638671875\n",
            "Epoch 47/50: loss = 0.08692412823438644, acc = 0.96875\n",
            "Epoch 48/50: loss = 0.09703637659549713, acc = 0.9609375\n",
            "Epoch 49/50: loss = 0.09798800945281982, acc = 0.962890625\n",
            "Epoch 50/50: loss = 0.12228741496801376, acc = 0.958984375\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE=16\n",
        "SEQ_SIZE=64\n",
        "model=trainingModel(uniques=len(charIndex),batchSize=BATCH_SIZE,seqSize=SEQ_SIZE)\n",
        "history = train(model=model,epochs=50,cp='modelV1',charIndex=charIndex,data=data,batchSize=BATCH_SIZE,seqSize=SEQ_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOYeovlUOoDu",
        "outputId": "ef7e93f4-25eb-41e9-b8df-e733b66db5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Na | Ti [0.25] | Soft Ra | Ki | Ta | Tin [1.00] | Na [0.50] | Na [0.25] | Na | Kat [1.00]+ | Na | Dha [0.50] | Ge | Ti [0.25] | Soft Ra | Ki | Ta | Dhin [0.50]+ | Na | Dhin1+ | Dha | Ti [0.25] | Ra | Ki | Ta | Dha [0.50]+ | Ti | Ge | Na | Dha | Tin | Dha | Ge | Tin | Na | Ge | Na\n",
            " | Na | Dha [0.50] | Ge | Dha | Ti [0.25] | Soft Ra | Ki | Ta | Dhin [1.00] | Dhin | Dha [0.50]+ | Ge | Ti [0.25] | fa | Ki | Ti | Dhin [1.00] | Na | Dha [0.20]++ | Ge | Ti | Ta | Na | Ge | Ti | Te | Na | Ge | Ti | Ta | Ge+ | Ti | Te | Dha | Dha | Ti | Te | Dha | Dha | Ti | Te | Dha | Dha1 | Dha1+ | Dhin1 | Dha [0.50]+ | Ge | Dhin1 | Na\n",
            "\n"
          ]
        }
      ],
      "source": [
        "l=[]\n",
        "while len(l)<=65: l+=generateSeq(65*9,\"modelV1\",indexChar).split(' | ')[1:]\n",
        "print(\" | \".join(l))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "p",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b03742df74d0d0fa3ea925eee82969db226f6d03a4743df24bc57ec65deca6ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
